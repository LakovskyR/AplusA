{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "614bd43c-6694-474c-98ff-26629a5b641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset: patients ===\n",
      "shape: (1000, 10)\n",
      "PatientID         object\n",
      "Age                int64\n",
      "Sex               object\n",
      "Pathology         object\n",
      "Treatment         object\n",
      "ResponseScore    float64\n",
      "Adherence        float64\n",
      "Satisfaction       int64\n",
      "Verbatim          object\n",
      "SurveyDate        object\n",
      "dtype: object\n",
      "nulls per column:\n",
      " PatientID         0\n",
      "Age               0\n",
      "Sex               0\n",
      "Pathology         0\n",
      "Treatment         0\n",
      "ResponseScore     0\n",
      "Adherence        20\n",
      "Satisfaction      0\n",
      "Verbatim         50\n",
      "SurveyDate        0\n",
      "dtype: int64\n",
      "unique counts (categorical candidates):\n",
      "PatientID     1000\n",
      "Sex              2\n",
      "Pathology        5\n",
      "Treatment        3\n",
      "Verbatim       841\n",
      "SurveyDate     316\n",
      "dtype: int64\n",
      "\n",
      "--- head ---\n",
      "           PatientID  Age Sex  Pathology Treatment  ResponseScore  Adherence  \\\n",
      "0  2842de9d43a98b53   58   M  Oncologie         B           3.54       0.86   \n",
      "1  fbeae7c18667b698   79   M     Asthme         B           2.49       0.92   \n",
      "2  acbbb742c7524cec   34   F  Oncologie         C           4.16       0.95   \n",
      "3  9f9853b3f1344419   39   F    DiabÃ¨te         A           1.60       0.75   \n",
      "4  e05184c1f58012ab   81   M    DiabÃ¨te         A           5.50       0.72   \n",
      "\n",
      "   Satisfaction                                           Verbatim  SurveyDate  \n",
      "0             5  Les rÃ©sultats sont mieux mais les comprimÃ©s so...  2024-03-19  \n",
      "1             5                                                NaN  2024-06-28  \n",
      "2             3  C'est acceptable malgrÃ© quelques dÃ©sagrÃ©ments....  2024-06-11  \n",
      "3             4  Ma situation est en amÃ©lioration progressive m...  2024-07-20  \n",
      "4             4  Jusqu'Ã  maintenant stable avec quelques effets...  2024-01-14  \n",
      "\n",
      "\n",
      "\n",
      "=== Dataset: docs ===\n",
      "shape: (1000, 7)\n",
      "DocID                object\n",
      "Specialty            object\n",
      "YearsPractice         int64\n",
      "PrescriptionFreq     object\n",
      "CriteriaScore       float64\n",
      "PreferBrand          object\n",
      "Comment              object\n",
      "dtype: object\n",
      "nulls per column:\n",
      " DocID                0\n",
      "Specialty            0\n",
      "YearsPractice        0\n",
      "PrescriptionFreq     0\n",
      "CriteriaScore        0\n",
      "PreferBrand          0\n",
      "Comment             30\n",
      "dtype: int64\n",
      "unique counts (categorical candidates):\n",
      "DocID               1000\n",
      "Specialty              5\n",
      "PrescriptionFreq       4\n",
      "PreferBrand            2\n",
      "Comment              799\n",
      "dtype: int64\n",
      "\n",
      "--- head ---\n",
      "               DocID  Specialty  YearsPractice PrescriptionFreq  CriteriaScore  \\\n",
      "0  cf440f61634b8b95    Pulmono             19           Weekly           0.43   \n",
      "1  33a123e5d474e8f3       Onco             11            Daily           0.42   \n",
      "2  2265f5336d7b6037  Endocrino              9           Weekly           0.45   \n",
      "3  bed7abeac56e560a         GP              5          Monthly           0.76   \n",
      "4  080f626098377e96     Cardio             15            Daily           0.14   \n",
      "\n",
      "  PreferBrand                                            Comment  \n",
      "0          No  Je m'appuie principalement sur les traitements...  \n",
      "1          No  Je valorise particuliÃ¨rement l'efficacitÃ© clin...  \n",
      "2         Yes  Pour ma pratique quotidienne l'Ã©ducation thÃ©ra...  \n",
      "3         Yes  J'intÃ¨gre systÃ©matiquement le profil individue...  \n",
      "4          No  Dans mon exercice le profil individuel spÃ©cifi...  \n",
      "\n",
      "\n",
      "\n",
      "=== Dataset: panel ===\n",
      "shape: (1000, 9)\n",
      "PatientID          object\n",
      "VisitDate          object\n",
      "VisitType          object\n",
      "Biomarker         float64\n",
      "ResponseScore     float64\n",
      "EventFlag           int64\n",
      "FutureProb        float64\n",
      "FutureResponse      int64\n",
      "Notes              object\n",
      "dtype: object\n",
      "nulls per column:\n",
      " PatientID          0\n",
      "VisitDate          0\n",
      "VisitType          0\n",
      "Biomarker         15\n",
      "ResponseScore      0\n",
      "EventFlag          0\n",
      "FutureProb         0\n",
      "FutureResponse     0\n",
      "Notes              0\n",
      "dtype: int64\n",
      "unique counts (categorical candidates):\n",
      "PatientID    400\n",
      "VisitDate    309\n",
      "VisitType      3\n",
      "Notes        855\n",
      "dtype: int64\n",
      "\n",
      "--- head ---\n",
      "           PatientID   VisitDate  VisitType  Biomarker  ResponseScore  \\\n",
      "0  c69770fe0c53d847  2024-06-29    Routine      42.77           5.14   \n",
      "1  1cda1ac09c3ec35c  2024-02-09    Routine      39.18           6.51   \n",
      "2  deab80f32a0cf02d  2024-09-26    Routine      44.27           2.35   \n",
      "3  f03c1a514b0fb29f  2024-05-09    Routine      28.02           1.70   \n",
      "4  f59f9cb8c2dc7f07  2024-08-30  Emergency      52.85           3.41   \n",
      "\n",
      "   EventFlag  FutureProb  FutureResponse  \\\n",
      "0          0       0.600               1   \n",
      "1          0       0.286               0   \n",
      "2          0       0.059               0   \n",
      "3          1       0.269               0   \n",
      "4          0       0.090               0   \n",
      "\n",
      "                                               Notes  \n",
      "0  Hydratation correcte constatÃ©e, imagerie compl...  \n",
      "1  AmÃ©lioration du souffle, Surveillance biologiq...  \n",
      "2  StabilitÃ© hÃ©modynamique observÃ©e, patient adhÃ¨...  \n",
      "3  AmÃ©lioration du souffle, Fatigue rÃ©siduelle me...  \n",
      "4  Douleurs thoraciques absentes, Cicatrisation e...  \n",
      "\n",
      "\n",
      "\n",
      "Numeric summary for patients\n",
      "                count       mean        std    min      25%    50%    75%  \\\n",
      "Age            1000.0  54.366000  13.944551  18.00  45.0000  54.00  64.00   \n",
      "ResponseScore  1000.0   2.856680   1.552671   0.07   1.6575   2.63   3.90   \n",
      "Adherence       980.0   0.845857   0.093449   0.55   0.7800   0.85   0.92   \n",
      "Satisfaction   1000.0   3.685000   1.104081   1.00   3.0000   4.00   5.00   \n",
      "\n",
      "                 max  \n",
      "Age            90.00  \n",
      "ResponseScore   8.13  \n",
      "Adherence       1.00  \n",
      "Satisfaction    5.00  \n",
      "\n",
      "\n",
      "Numeric summary for docs\n",
      "                count      mean       std   min   25%   50%    75%    max\n",
      "YearsPractice  1000.0  10.06500  3.154160  2.00  8.00  10.0  12.00  22.00\n",
      "CriteriaScore  1000.0   0.50006  0.218438  0.02  0.33   0.5   0.67   0.97\n",
      "\n",
      "\n",
      "Numeric summary for panel\n",
      "                 count       mean        std   min     25%      50%       75%  \\\n",
      "Biomarker        985.0  50.611117  14.515584  5.00  40.260  50.4600  60.89000   \n",
      "ResponseScore   1000.0   2.845270   1.586403  0.12   1.600   2.6350   3.86000   \n",
      "EventFlag       1000.0   0.089000   0.284886  0.00   0.000   0.0000   0.00000   \n",
      "FutureProb      1000.0   0.188371   0.129634  0.00   0.085   0.1835   0.27025   \n",
      "FutureResponse  1000.0   0.011000   0.104355  0.00   0.000   0.0000   0.00000   \n",
      "\n",
      "                   max  \n",
      "Biomarker       92.110  \n",
      "ResponseScore    8.230  \n",
      "EventFlag        1.000  \n",
      "FutureProb       0.625  \n",
      "FutureResponse   1.000  \n",
      "\n",
      "\n",
      "Patients ResponseScore vs Adherence corr: 0.23594677826296007\n",
      "Docs YearsPractice vs PreferBrand corr: 0.21413181622290345\n",
      "Panel FutureProb vs FutureResponse corr: 0.2936821850272409\n",
      "All basic shape checks passed (1000 rows each)\n",
      "Unique PatientIDs (patients): 1000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"C:/Users/lakovskr/Desktop/portfolio/AplusA_PoC/data_raw\")  # adapte si nÃ©cessaire\n",
    "\n",
    "files = {\n",
    "    \"patients\": DATA_DIR/\"patients_survey.csv\",\n",
    "    \"docs\": DATA_DIR/\"docs_survey.csv\",\n",
    "    \"panel\": DATA_DIR/\"panel_longitudinal.csv\"\n",
    "}\n",
    "\n",
    "# 1) Chargement\n",
    "dfs = {k: pd.read_csv(path, parse_dates=True, dayfirst=False) for k, path in files.items()}\n",
    "\n",
    "# 2) Basic info & counts\n",
    "for name, df in dfs.items():\n",
    "    print(\"=== Dataset:\", name, \"===\")\n",
    "    print(\"shape:\", df.shape)\n",
    "    print(df.dtypes)\n",
    "    print(\"nulls per column:\\n\", df.isna().sum())\n",
    "    print(\"unique counts (categorical candidates):\")\n",
    "    print(df.select_dtypes(include=['object','category']).nunique())\n",
    "    print(\"\\n--- head ---\\n\", df.head(5))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "# 3) Quick numeric stats and ranges\n",
    "for name, df in dfs.items():\n",
    "    nums = df.select_dtypes(include=[np.number])\n",
    "    if not nums.empty:\n",
    "        print(\"Numeric summary for\", name)\n",
    "        print(nums.describe().T[['count','mean','std','min','25%','50%','75%','max']])\n",
    "    print(\"\\n\")\n",
    "\n",
    "# 4) Spot-check correlations requested in spec\n",
    "if 'ResponseScore' in dfs['patients'].columns and 'Adherence' in dfs['patients'].columns:\n",
    "    print(\"Patients ResponseScore vs Adherence corr:\", dfs['patients'][['ResponseScore','Adherence']].corr().iloc[0,1])\n",
    "\n",
    "if 'YearsPractice' in dfs['docs'].columns and 'PreferBrand' in dfs['docs'].columns:\n",
    "    # convert PreferBrand to 0/1 if needed\n",
    "    d = dfs['docs'].copy()\n",
    "    if d['PreferBrand'].dtype == object:\n",
    "        d['PreferBrand_bin'] = d['PreferBrand'].map({'Yes':1,'No':0})\n",
    "    else:\n",
    "        d['PreferBrand_bin'] = d['PreferBrand']\n",
    "    print(\"Docs YearsPractice vs PreferBrand corr:\", d[['YearsPractice','PreferBrand_bin']].corr().iloc[0,1])\n",
    "\n",
    "if 'FutureProb' in dfs['panel'].columns and 'FutureResponse' in dfs['panel'].columns:\n",
    "    print(\"Panel FutureProb vs FutureResponse corr:\", dfs['panel'][['FutureProb','FutureResponse']].corr().iloc[0,1])\n",
    "\n",
    "# 5) Quick validation rules\n",
    "# - exactly 1000 lines in patients and docs\n",
    "assert dfs['patients'].shape[0] == 1000, \"patients must have 1000 rows\"\n",
    "assert dfs['docs'].shape[0] == 1000, \"docs must have 1000 rows\"\n",
    "assert dfs['panel'].shape[0] == 1000, \"panel must have 1000 rows\"\n",
    "\n",
    "print(\"All basic shape checks passed (1000 rows each)\")\n",
    "\n",
    "# 6) Check patientID uniqueness (patients)\n",
    "if 'PatientID' in dfs['patients'].columns:\n",
    "    print(\"Unique PatientIDs (patients):\", dfs['patients']['PatientID'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "242428f3-4b1c-4433-9d8a-69c003392fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lakovskr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1241: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visits distribution:\n",
      " n_visits\n",
      "1    106\n",
      "2    113\n",
      "3     88\n",
      "4     61\n",
      "5     32\n",
      "Name: count, dtype: int64\n",
      "FutureResponse balance:\n",
      " {0: 0.872, 1: 0.128}\n",
      "FutureProb mean: 0.31524699999999994\n",
      "Saved cleaned CSVs and parquet.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(r\"C:/Users/lakovskr/Desktop/portfolio/AplusA_PoC/data_raw\")\n",
    "OUT_PARQUET = Path(r\"C:/Users/lakovskr/Desktop/portfolio/AplusA_PoC/data_parquet\")\n",
    "OUT_PARQUET.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# load\n",
    "patients = pd.read_csv(DATA_DIR/\"patients_survey.csv\")\n",
    "docs     = pd.read_csv(DATA_DIR/\"docs_survey.csv\")\n",
    "panel    = pd.read_csv(DATA_DIR/\"panel_longitudinal.csv\")\n",
    "\n",
    "# 1) convert dates\n",
    "patients['SurveyDate'] = pd.to_datetime(patients['SurveyDate'], errors='coerce')\n",
    "panel['VisitDate'] = pd.to_datetime(panel['VisitDate'], errors='coerce')\n",
    "\n",
    "# 2) missing flags\n",
    "patients['Adherence_missing'] = patients['Adherence'].isna().astype(int)\n",
    "patients['Verbatim_missing'] = patients['Verbatim'].isna().astype(int)\n",
    "docs['Comment_missing'] = docs['Comment'].isna().astype(int)\n",
    "panel['Biomarker_missing'] = panel['Biomarker'].isna().astype(int)\n",
    "\n",
    "# 3) impute numeric missing\n",
    "patients['Adherence'] = patients['Adherence'].fillna(patients['Adherence'].median())\n",
    "global_biom_median = panel['Biomarker'].median()\n",
    "panel['Biomarker'] = panel.groupby('PatientID')['Biomarker'].transform(lambda g: g.fillna(g.median()))\n",
    "panel['Biomarker'] = panel['Biomarker'].fillna(global_biom_median)\n",
    "\n",
    "# 4) Verbatim: fill placeholder if any left\n",
    "patients['Verbatim'] = patients['Verbatim'].fillna(\"No comment\")\n",
    "\n",
    "# 5) Visits per patient summary (useful feature)\n",
    "visits_per_patient = panel.groupby('PatientID').size().rename('n_visits')\n",
    "print(\"Visits distribution:\\n\", visits_per_patient.value_counts().sort_index())\n",
    "\n",
    "# 6) Check class balance for panel target\n",
    "print(\"FutureResponse balance:\\n\", panel['FutureResponse'].value_counts(normalize=True).to_dict())\n",
    "print(\"FutureProb mean:\", panel['FutureProb'].mean())\n",
    "\n",
    "# 7) Save cleaned CSV + parquet\n",
    "patients.to_csv(DATA_DIR/\"patients_survey_clean.csv\", index=False)\n",
    "docs.to_csv(DATA_DIR/\"docs_survey_clean.csv\", index=False)\n",
    "panel.to_csv(DATA_DIR/\"panel_longitudinal_clean.csv\", index=False)\n",
    "\n",
    "patients.to_parquet(OUT_PARQUET/\"patients_survey.parquet\", index=False)\n",
    "docs.to_parquet(OUT_PARQUET/\"docs_survey.parquet\", index=False)\n",
    "panel.to_parquet(OUT_PARQUET/\"panel_longitudinal.parquet\", index=False)\n",
    "\n",
    "print(\"Saved cleaned CSVs and parquet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e8ec554-ff4b-43ee-a661-6a0df09ecc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "base = Path(r\"C:/Users/lakovskr/Desktop/portfolio/AplusA_PoC\")\n",
    "data_raw = base / \"data_raw\"\n",
    "silver = base / \"silver\"\n",
    "silver.mkdir(exist_ok=True)\n",
    "\n",
    "# List the cleaned CSVs you want to convert\n",
    "csv_files = [\n",
    "    \"patients_survey_clean.csv\",\n",
    "    \"docs_survey_clean.csv\",\n",
    "    \"panel_longitudinal_clean.csv\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37a53fe6-6bee-4c72-bfd1-7170cb42b632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved C:\\Users\\lakovskr\\Desktop\\portfolio\\AplusA_PoC\\silver\\patients_survey_clean.parquet\n",
      "Saved C:\\Users\\lakovskr\\Desktop\\portfolio\\AplusA_PoC\\silver\\docs_survey_clean.parquet\n",
      "Saved C:\\Users\\lakovskr\\Desktop\\portfolio\\AplusA_PoC\\silver\\panel_longitudinal_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "for fname in csv_files:\n",
    "    csv_path = data_raw / fname\n",
    "    df = pd.read_csv(csv_path)\n",
    "    parquet_path = silver / fname.replace(\"_clean.csv\", \"_clean.parquet\")\n",
    "    df.to_parquet(parquet_path, index=False)\n",
    "    print(f\"Saved {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82544d5c-529a-4364-b81a-273a7679e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs_survey_clean.parquet -> (1000, 8)\n",
      "panel_longitudinal_clean.parquet -> (1000, 10)\n",
      "patients_survey_clean.parquet -> (1000, 12)\n"
     ]
    }
   ],
   "source": [
    "for f in silver.glob(\"*.parquet\"):\n",
    "    print(f.name, \"->\", pd.read_parquet(f).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fad4a774-7474-4d52-b441-484fc21add04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SILVER layer...\n",
      "  patients: (1000, 12)\n",
      "  docs: (1000, 8)\n",
      "  panel: (1000, 10)\n",
      "\n",
      "Enforcing data types...\n",
      "\n",
      "Aggregating panel data to patient level...\n",
      "  panel_agg: (400, 17)\n",
      "\n",
      "Building patients_features table...\n",
      "  patients_features: (1000, 35)\n",
      "\n",
      "Building docs_summary_agg table...\n",
      "  docs_summary_agg: (5, 7)\n",
      "\n",
      "Building patient_panel_joined table...\n",
      "  patient_panel_joined: (1000, 21)\n",
      "\n",
      "Saving GOLD tables...\n",
      "âœ“ patients_features: (1000, 35)\n",
      "âœ“ docs_survey: (1000, 8)\n",
      "âœ“ docs_summary_agg: (5, 7)\n",
      "âœ“ patient_panel_joined: (1000, 21)\n",
      "\n",
      "================================================================================\n",
      "VALIDATION: PATIENTS_FEATURES\n",
      "================================================================================\n",
      "\n",
      "Columns: ['PatientID', 'Age', 'Sex', 'Pathology', 'Treatment', 'ResponseScore', 'Adherence', 'Satisfaction', 'Verbatim', 'SurveyDate', 'Adherence_missing', 'Verbatim_missing', 'n_visits', 'first_visit', 'last_visit', 'biomarker_mean', 'biomarker_std', 'biomarker_min', 'biomarker_max', 'response_mean', 'response_std', 'future_resp_rate', 'future_prob_mean', 'event_count', 'event_rate', 'days_since_last_visit', 'months_active', 'visits_per_month', 'age_bucket', 'treatment_num', 'satisfied', 'high_adherence', 'high_responder', 'adherence_cat', 'response_cat']\n",
      "\n",
      "Sample rows:\n",
      "          PatientID  Age Sex Treatment  Adherence  n_visits  response_mean adherence_cat\n",
      "0  2842de9d43a98b53   58   M         B       0.86         2           3.23        80-95%\n",
      "1  fbeae7c18667b698   79   M         B       0.92         5           2.51        80-95%\n",
      "2  acbbb742c7524cec   34   F         C       0.95         3           2.07        80-95%\n",
      "\n",
      "Numerical Summary:\n",
      "           Age  Adherence  Satisfaction  n_visits  biomarker_mean  \\\n",
      "count  1000.00    1000.00       1000.00   1000.00         1000.00   \n",
      "mean     54.37       0.85          3.68      1.00           50.07   \n",
      "std      13.94       0.09          1.10      1.46            7.08   \n",
      "min      18.00       0.55          1.00      0.00           12.67   \n",
      "25%      45.00       0.78          3.00      0.00           50.14   \n",
      "50%      54.00       0.85          4.00      0.00           50.14   \n",
      "75%      64.00       0.92          5.00      2.00           50.14   \n",
      "max      90.00       1.00          5.00      5.00           82.16   \n",
      "\n",
      "       response_mean  \n",
      "count        1000.00  \n",
      "mean            2.91  \n",
      "std             1.45  \n",
      "min             0.07  \n",
      "25%             1.87  \n",
      "50%             2.77  \n",
      "75%             3.81  \n",
      "max             8.13  \n",
      "\n",
      "================================================================================\n",
      "VALIDATION: DOCS_SUMMARY_AGG\n",
      "================================================================================\n",
      "Specialty  n_docs  avg_years_practice  median_years_practice  pct_prefer_brand  avg_criteria_score  pct_high_freq\n",
      "   Cardio     197           10.309645                   10.0              27.4            0.491675            0.0\n",
      "Endocrino     158            9.493671                    9.0              23.4            0.502405            0.0\n",
      "       GP     405            9.967901                   10.0              24.4            0.505432            0.0\n",
      "     Onco     102           10.156863                   10.0              28.4            0.496471            0.0\n",
      "  Pulmono     138           10.586957                   10.0              34.8            0.496232            0.0\n",
      "\n",
      "================================================================================\n",
      "VALIDATION: PATIENT_PANEL_JOINED\n",
      "================================================================================\n",
      "\n",
      "Columns: ['PatientID', 'VisitDate', 'VisitType', 'Biomarker', 'ResponseScore_visit', 'EventFlag', 'FutureProb', 'FutureResponse', 'Notes', 'Biomarker_missing', 'Age', 'Sex', 'Pathology', 'Treatment', 'Adherence', 'Satisfaction', 'ResponseScore_baseline', 'first_visit', 'days_from_first_visit', 'visit_number', 'age_bucket']\n",
      "\n",
      "Sample rows:\n",
      "            PatientID  VisitDate  visit_number  Biomarker  ResponseScore_visit  EventFlag\n",
      "888  0057fe5da0e0a02c 2024-04-22             1      55.16                 0.97          0\n",
      "634  0057fe5da0e0a02c 2024-08-30             2      56.56                 1.56          1\n",
      "490  0057fe5da0e0a02c 2024-10-25             3      37.30                 1.66          0\n",
      "630  0088d81eeae59255 2024-01-01             1      80.60                 1.60          0\n",
      "289  0088d81eeae59255 2024-02-02             2      65.82                 2.39          0\n",
      "\n",
      "================================================================================\n",
      "GOLD LAYER BUILD COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build GOLD layer from SILVER parquet files\n",
    "Creates analytical models ready for BI/ML consumption\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "BASE = Path(r\"C:/Users/lakovskr/Desktop/portfolio/AplusA_PoC\")\n",
    "SILVER = BASE / \"silver\"\n",
    "GOLD = BASE / \"gold\"\n",
    "GOLD.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD SILVER TABLES\n",
    "# ============================================================================\n",
    "print(\"Loading SILVER layer...\")\n",
    "patients = pd.read_parquet(SILVER / \"patients_survey_clean.parquet\")\n",
    "docs = pd.read_parquet(SILVER / \"docs_survey_clean.parquet\")\n",
    "panel = pd.read_parquet(SILVER / \"panel_longitudinal_clean.parquet\")\n",
    "\n",
    "print(f\"  patients: {patients.shape}\")\n",
    "print(f\"  docs: {docs.shape}\")\n",
    "print(f\"  panel: {panel.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DATA TYPE ENFORCEMENT\n",
    "# ============================================================================\n",
    "print(\"\\nEnforcing data types...\")\n",
    "patients['SurveyDate'] = pd.to_datetime(patients['SurveyDate'], errors='coerce')\n",
    "panel['VisitDate'] = pd.to_datetime(panel['VisitDate'], errors='coerce')\n",
    "patients['PatientID'] = patients['PatientID'].astype(str)\n",
    "panel['PatientID'] = panel['PatientID'].astype(str)\n",
    "docs['DocID'] = docs['DocID'].astype(str)\n",
    "\n",
    "# ============================================================================\n",
    "# BUILD PANEL AGGREGATES (Patient-level features from visits)\n",
    "# ============================================================================\n",
    "print(\"\\nAggregating panel data to patient level...\")\n",
    "panel_agg = panel.groupby('PatientID').agg(\n",
    "    n_visits=('VisitDate', 'count'),\n",
    "    first_visit=('VisitDate', 'min'),\n",
    "    last_visit=('VisitDate', 'max'),\n",
    "    biomarker_mean=('Biomarker', 'mean'),\n",
    "    biomarker_std=('Biomarker', 'std'),\n",
    "    biomarker_min=('Biomarker', 'min'),\n",
    "    biomarker_max=('Biomarker', 'max'),\n",
    "    response_mean=('ResponseScore', 'mean'),\n",
    "    response_std=('ResponseScore', 'std'),\n",
    "    future_resp_rate=('FutureResponse', 'mean'),\n",
    "    future_prob_mean=('FutureProb', 'mean'),\n",
    "    event_count=('EventFlag', 'sum'),\n",
    "    event_rate=('EventFlag', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Fill NaN std with 0 (single visit cases)\n",
    "panel_agg['biomarker_std'] = panel_agg['biomarker_std'].fillna(0)\n",
    "panel_agg['response_std'] = panel_agg['response_std'].fillna(0)\n",
    "\n",
    "# Recency: days since last visit\n",
    "ref_date = panel['VisitDate'].max()\n",
    "panel_agg['days_since_last_visit'] = (ref_date - panel_agg['last_visit']).dt.days\n",
    "\n",
    "# Visit frequency: visits per month active\n",
    "panel_agg['months_active'] = ((panel_agg['last_visit'] - panel_agg['first_visit']).dt.days / 30.44).clip(lower=1)\n",
    "panel_agg['visits_per_month'] = panel_agg['n_visits'] / panel_agg['months_active']\n",
    "\n",
    "print(f\"  panel_agg: {panel_agg.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# BUILD PATIENTS_FEATURES (Main analytical table)\n",
    "# ============================================================================\n",
    "print(\"\\nBuilding patients_features table...\")\n",
    "patients_features = patients.merge(panel_agg, on='PatientID', how='left')\n",
    "\n",
    "# Age buckets\n",
    "patients_features['age_bucket'] = pd.cut(\n",
    "    patients_features['Age'],\n",
    "    bins=[17, 30, 45, 60, 75, 120],\n",
    "    labels=['18-30', '31-45', '46-60', '61-75', '76+']\n",
    ")\n",
    "\n",
    "# Treatment numeric encoding\n",
    "treatment_map = {'A': 0, 'B': 1, 'C': 2}\n",
    "patients_features['treatment_num'] = patients_features['Treatment'].map(treatment_map)\n",
    "\n",
    "# Binary flags\n",
    "patients_features['satisfied'] = (patients_features['Satisfaction'] >= 4).astype(int)\n",
    "patients_features['high_adherence'] = (patients_features['Adherence'] >= 0.8).astype(int)\n",
    "patients_features['high_responder'] = (patients_features['ResponseScore'] >= 7).astype(int)\n",
    "\n",
    "# Adherence categories\n",
    "patients_features['adherence_cat'] = pd.cut(\n",
    "    patients_features['Adherence'],\n",
    "    bins=[-0.01, 0.6, 0.8, 0.95, 1.01],\n",
    "    labels=['<60%', '60-80%', '80-95%', '95-100%']\n",
    ").astype(str)\n",
    "\n",
    "# Response categories\n",
    "patients_features['response_cat'] = pd.cut(\n",
    "    patients_features['ResponseScore'],\n",
    "    bins=[-0.01, 4, 7, 10.01],\n",
    "    labels=['Low (0-4)', 'Medium (4-7)', 'High (7-10)']\n",
    ").astype(str)\n",
    "\n",
    "# Fill NaNs for patients without panel visits\n",
    "fill_dict = {\n",
    "    'n_visits': 0,\n",
    "    'event_count': 0,\n",
    "    'event_rate': 0,\n",
    "    'future_resp_rate': 0,\n",
    "    'future_prob_mean': 0,\n",
    "    'days_since_last_visit': 999,\n",
    "    'visits_per_month': 0,\n",
    "    'months_active': 0\n",
    "}\n",
    "patients_features = patients_features.fillna(fill_dict)\n",
    "\n",
    "# Impute biomarker/response means with survey baseline\n",
    "patients_features['biomarker_mean'] = patients_features['biomarker_mean'].fillna(\n",
    "    patients_features['biomarker_mean'].median()\n",
    ")\n",
    "patients_features['response_mean'] = patients_features['response_mean'].fillna(\n",
    "    patients_features['ResponseScore']\n",
    ")\n",
    "\n",
    "# Convert numeric types\n",
    "int_cols = ['n_visits', 'event_count', 'days_since_last_visit']\n",
    "for col in int_cols:\n",
    "    patients_features[col] = patients_features[col].astype(int)\n",
    "\n",
    "print(f\"  patients_features: {patients_features.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# BUILD DOCS_SUMMARY_AGG (Specialty-level aggregates)\n",
    "# ============================================================================\n",
    "print(\"\\nBuilding docs_summary_agg table...\")\n",
    "docs_summary_agg = docs.groupby('Specialty').agg(\n",
    "    n_docs=('DocID', 'count'),\n",
    "    avg_years_practice=('YearsPractice', 'mean'),\n",
    "    median_years_practice=('YearsPractice', 'median'),\n",
    "    pct_prefer_brand=('PreferBrand', lambda x: (x == 'Yes').sum() / x.count()),\n",
    "    avg_criteria_score=('CriteriaScore', 'mean'),\n",
    "    pct_high_freq=('PrescriptionFreq', lambda x: (x == 'High').sum() / x.count())\n",
    ").reset_index()\n",
    "\n",
    "# Round percentages\n",
    "docs_summary_agg['pct_prefer_brand'] = (docs_summary_agg['pct_prefer_brand'] * 100).round(1)\n",
    "docs_summary_agg['pct_high_freq'] = (docs_summary_agg['pct_high_freq'] * 100).round(1)\n",
    "\n",
    "print(f\"  docs_summary_agg: {docs_summary_agg.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# BUILD PATIENT_PANEL_JOINED (Visit-level analytical table)\n",
    "# ============================================================================\n",
    "print(\"\\nBuilding patient_panel_joined table...\")\n",
    "# NOTE: Using explicit suffixes to handle ResponseScore column collision\n",
    "# - ResponseScore_visit: actual response at each visit (from panel)\n",
    "# - ResponseScore_baseline: initial survey response (from patients)\n",
    "patient_panel_joined = panel.merge(\n",
    "    patients[['PatientID', 'Age', 'Sex', 'Pathology', 'Treatment', \n",
    "              'Adherence', 'Satisfaction', 'ResponseScore']],\n",
    "    on='PatientID',\n",
    "    how='left',\n",
    "    validate='m:1',\n",
    "    suffixes=('_visit', '_baseline')\n",
    ")\n",
    "\n",
    "# Add first visit per patient\n",
    "first_visit = panel.groupby('PatientID')['VisitDate'].min().rename('first_visit').reset_index()\n",
    "patient_panel_joined = patient_panel_joined.merge(first_visit, on='PatientID', how='left')\n",
    "\n",
    "# Days from first visit\n",
    "patient_panel_joined['days_from_first_visit'] = (\n",
    "    patient_panel_joined['VisitDate'] - patient_panel_joined['first_visit']\n",
    ").dt.days\n",
    "\n",
    "# Visit sequence number\n",
    "patient_panel_joined = patient_panel_joined.sort_values(['PatientID', 'VisitDate'])\n",
    "patient_panel_joined['visit_number'] = patient_panel_joined.groupby('PatientID').cumcount() + 1\n",
    "\n",
    "# Age bucket\n",
    "patient_panel_joined['age_bucket'] = pd.cut(\n",
    "    patient_panel_joined['Age'],\n",
    "    bins=[17, 30, 45, 60, 75, 120],\n",
    "    labels=['18-30', '31-45', '46-60', '61-75', '76+']\n",
    ")\n",
    "\n",
    "print(f\"  patient_panel_joined: {patient_panel_joined.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE GOLD TABLES\n",
    "# ============================================================================\n",
    "print(\"\\nSaving GOLD tables...\")\n",
    "\n",
    "# Parquet (compressed, best for analytics)\n",
    "patients_features.to_parquet(GOLD / \"patients_features.parquet\", index=False)\n",
    "docs.to_parquet(GOLD / \"docs_survey.parquet\", index=False)  # Keep full table\n",
    "docs_summary_agg.to_parquet(GOLD / \"docs_summary_agg.parquet\", index=False)\n",
    "patient_panel_joined.to_parquet(GOLD / \"patient_panel_joined.parquet\", index=False)\n",
    "\n",
    "# CSV (for compatibility)\n",
    "patients_features.to_csv(GOLD / \"patients_features.csv\", index=False)\n",
    "docs.to_csv(GOLD / \"docs_survey.csv\", index=False)\n",
    "docs_summary_agg.to_csv(GOLD / \"docs_summary_agg.csv\", index=False)\n",
    "patient_panel_joined.to_csv(GOLD / \"patient_panel_joined.csv\", index=False)\n",
    "\n",
    "print(\"âœ“ patients_features:\", patients_features.shape)\n",
    "print(\"âœ“ docs_survey:\", docs.shape)\n",
    "print(\"âœ“ docs_summary_agg:\", docs_summary_agg.shape)\n",
    "print(\"âœ“ patient_panel_joined:\", patient_panel_joined.shape)\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDATION OUTPUTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VALIDATION: PATIENTS_FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nColumns:\", patients_features.columns.tolist())\n",
    "print(\"\\nSample rows:\")\n",
    "print(patients_features.head(3)[['PatientID', 'Age', 'Sex', 'Treatment', 'Adherence', \n",
    "                                   'n_visits', 'response_mean', 'adherence_cat']].to_string())\n",
    "print(\"\\nNumerical Summary:\")\n",
    "print(patients_features[['Age', 'Adherence', 'Satisfaction', 'n_visits', \n",
    "                          'biomarker_mean', 'response_mean']].describe().round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VALIDATION: DOCS_SUMMARY_AGG\")\n",
    "print(\"=\" * 80)\n",
    "print(docs_summary_agg.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VALIDATION: PATIENT_PANEL_JOINED\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nColumns:\", patient_panel_joined.columns.tolist())\n",
    "print(\"\\nSample rows:\")\n",
    "print(patient_panel_joined.head(5)[['PatientID', 'VisitDate', 'visit_number', \n",
    "                                     'Biomarker', 'ResponseScore_visit', 'EventFlag']].to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GOLD LAYER BUILD COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c45d7cc9-3d96-4874-b464-f409ced439d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ML TRAINING PIPELINE - PATIENT RESPONSE PREDICTION\n",
      "================================================================================\n",
      "\n",
      "Loading gold table...\n",
      "  Loaded: (1000, 35)\n",
      "\n",
      "Creating target variable...\n",
      "  Checking target balance at different thresholds:\n",
      "    future_resp_rate > 0: 11.1% positive\n",
      "    future_resp_rate > 0.3: 7.5% positive\n",
      "    future_resp_rate > 0.5: 2.0% positive\n",
      "\n",
      "  âœ“ Using: future_resp_rate > 0\n",
      "    Class balance: {0: 0.889, 1: 0.111}\n",
      "\n",
      "Preparing features...\n",
      "  Candidate features: 26\n",
      "\n",
      "Encoding categorical features...\n",
      "  Categorical columns: ['Sex', 'Pathology', 'Treatment', 'adherence_cat', 'response_cat']\n",
      "    âœ“ Encoded: Sex\n",
      "    âœ“ Encoded: Pathology\n",
      "    âœ“ Encoded: Treatment\n",
      "    âœ“ Encoded: adherence_cat\n",
      "    âœ“ Encoded: response_cat\n",
      "\n",
      "  Final feature count: 26\n",
      "\n",
      "  Handling missing values:\n",
      "    Features with NaN: {'biomarker_std': 600, 'biomarker_min': 600, 'biomarker_max': 600, 'response_std': 600}\n",
      "    âœ“ Filled with median\n",
      "\n",
      "Final dataset: (1000, 26)\n",
      "Features used: ['Age', 'Sex', 'Pathology', 'Treatment', 'Adherence', 'Satisfaction', 'Adherence_missing', 'Verbatim_missing', 'n_visits', 'biomarker_mean', 'biomarker_std', 'biomarker_min', 'biomarker_max', 'response_mean', 'response_std', 'event_count', 'event_rate', 'days_since_last_visit', 'months_active', 'visits_per_month', 'treatment_num', 'satisfied', 'high_adherence', 'high_responder', 'adherence_cat', 'response_cat']\n",
      "Class balance: {0: 0.889, 1: 0.111}\n",
      "\n",
      "Splitting data...\n",
      "  Train: (800, 26)\n",
      "  Test: (200, 26)\n",
      "\n",
      "Setting up models...\n",
      "  âš  XGBoost not available\n",
      "  âš  LightGBM not available\n",
      "\n",
      "  Models to train: ['logreg', 'rf']\n",
      "\n",
      "================================================================================\n",
      "TRAINING MODELS\n",
      "================================================================================\n",
      "\n",
      "[LOGREG]\n",
      "----------------------------------------\n",
      "  AUC:       0.921\n",
      "  PR-AUC:    0.477\n",
      "  Precision: 0.404\n",
      "  Recall:    0.955\n",
      "  F1:        0.568\n",
      "  Brier:     0.121\n",
      "  âœ“ Saved: model_logreg.joblib\n",
      "\n",
      "[RF]\n",
      "----------------------------------------\n",
      "  AUC:       0.936\n",
      "  PR-AUC:    0.638\n",
      "  Precision: 0.667\n",
      "  Recall:    0.545\n",
      "  F1:        0.600\n",
      "  Brier:     0.063\n",
      "  âœ“ Saved: model_rf.joblib\n",
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON\n",
      "================================================================================\n",
      "\n",
      " model      auc   pr_auc  precision   recall       f1    brier\n",
      "    rf 0.935904 0.638297   0.666667 0.545455 0.600000 0.062946\n",
      "logreg 0.920838 0.476892   0.403846 0.954545 0.567568 0.120512\n",
      "\n",
      "âœ“ Saved: model_scores.csv\n",
      "\n",
      "ðŸ† Best model: RF (AUC=0.936)\n",
      "\n",
      "================================================================================\n",
      "FEATURE IMPORTANCE\n",
      "================================================================================\n",
      "\n",
      "âœ“ Saved: feature_importance_rf.csv\n",
      "\n",
      "Top 10 features:\n",
      "              feature  importance\n",
      "     visits_per_month    0.150205\n",
      "days_since_last_visit    0.148663\n",
      "        months_active    0.106694\n",
      "             n_visits    0.094349\n",
      "        response_mean    0.091418\n",
      "         response_std    0.083186\n",
      "        biomarker_min    0.070997\n",
      "       biomarker_mean    0.050962\n",
      "        biomarker_max    0.045856\n",
      "        biomarker_std    0.037178\n",
      "âœ“ Saved: feature_importance_rf.png\n",
      "\n",
      "================================================================================\n",
      "SHAP EXPLANATIONS\n",
      "================================================================================\n",
      "âš  SHAP computation failed: No module named 'shap'\n",
      "  Continuing without SHAP explanations...\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE CURVES\n",
      "================================================================================\n",
      "âœ“ Saved: roc_curve_best.png\n",
      "âœ“ Saved: pr_curve_best.png\n",
      "\n",
      "================================================================================\n",
      "GENERATING FULL DATASET PREDICTIONS\n",
      "================================================================================\n",
      "âœ“ Saved: predictions_full_bestmodel.csv (1000 patients)\n",
      "\n",
      "Risk distribution:\n",
      "risk_category\n",
      "Low       237\n",
      "Medium     88\n",
      "High       75\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "GENERATING REPORT\n",
      "================================================================================\n",
      "âœ“ Saved: model_report.txt\n",
      "\n",
      "================================================================================\n",
      "PIPELINE COMPLETE\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‚ All outputs saved to: C:\\Users\\lakovskr\\Desktop\\portfolio\\AplusA_PoC\\gold\n",
      "\n",
      "Files created:\n",
      "  â€¢ model_*.joblib (2 models)\n",
      "  â€¢ predictions_*.csv (2 + 1 files)\n",
      "  â€¢ model_scores.csv\n",
      "  â€¢ feature_importance_*.csv/.png\n",
      "  â€¢ shap_summary_*.png\n",
      "  â€¢ roc_curve_best.png\n",
      "  â€¢ pr_curve_best.png\n",
      "  â€¢ model_report.txt\n",
      "\n",
      "ðŸ† Best model: RF\n",
      "   AUC: 0.936\n",
      "   Ready for deployment!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ML Training & Comparison Pipeline - FIXED VERSION\n",
    "Trains multiple models to predict patient future response\n",
    "Handles categorical features, provides SHAP explanations, saves all outputs\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, \n",
    "                             precision_recall_curve, precision_score, \n",
    "                             recall_score, f1_score, brier_score_loss,\n",
    "                             roc_curve)\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "BASE = Path(r\"C:/Users/lakovskr/Desktop/portfolio/AplusA_PoC\")\n",
    "GOLD = BASE / \"gold\"\n",
    "OUT = GOLD  # save outputs into gold\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ML TRAINING PIPELINE - PATIENT RESPONSE PREDICTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "print(\"\\nLoading gold table...\")\n",
    "df = pd.read_parquet(GOLD / \"patients_features.parquet\")\n",
    "print(f\"  Loaded: {df.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TARGET CREATION\n",
    "# ============================================================================\n",
    "print(\"\\nCreating target variable...\")\n",
    "# Option 1: Binary target from future_resp_rate\n",
    "if 'future_resp_rate' in df.columns:\n",
    "    # Check different thresholds\n",
    "    print(\"  Checking target balance at different thresholds:\")\n",
    "    for thresh in [0, 0.3, 0.5]:\n",
    "        pct = (df['future_resp_rate'] > thresh).mean()\n",
    "        print(f\"    future_resp_rate > {thresh}: {pct:.1%} positive\")\n",
    "    \n",
    "    # Use threshold 0 (any future response)\n",
    "    df['y'] = (df['future_resp_rate'] > 0).astype(int)\n",
    "    print(f\"\\n  âœ“ Using: future_resp_rate > 0\")\n",
    "    print(f\"    Class balance: {df['y'].value_counts(normalize=True).to_dict()}\")\n",
    "else:\n",
    "    raise ValueError(\"No future_resp_rate in patients_features\")\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "print(\"\\nPreparing features...\")\n",
    "\n",
    "# Drop non-feature columns (FIXED: removed ResponseScore_baseline - doesn't exist here)\n",
    "drop_cols = [\n",
    "    'PatientID', 'Verbatim', 'SurveyDate', \n",
    "    'first_visit', 'last_visit', 'age_bucket',\n",
    "    'y', 'future_resp_rate', 'future_prob_mean',  # target & related\n",
    "    'ResponseScore'  # Already have response_mean from panel\n",
    "]\n",
    "\n",
    "candidate_features = [c for c in df.columns if c not in drop_cols]\n",
    "print(f\"  Candidate features: {len(candidate_features)}\")\n",
    "\n",
    "# Create feature matrix\n",
    "X = df[candidate_features].copy()\n",
    "\n",
    "# Handle categorical features (FIXED: encode instead of dropping)\n",
    "print(\"\\nEncoding categorical features...\")\n",
    "categorical_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "if categorical_cols:\n",
    "    print(f\"  Categorical columns: {categorical_cols}\")\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "            print(f\"    âœ“ Encoded: {col}\")\n",
    "\n",
    "# Convert to numeric and handle missing values (FIXED: use median instead of 0)\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "print(f\"\\n  Final feature count: {X.shape[1]}\")\n",
    "\n",
    "# Check missing values\n",
    "missing = X.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(f\"\\n  Handling missing values:\")\n",
    "    print(f\"    Features with NaN: {missing[missing > 0].to_dict()}\")\n",
    "    X = X.fillna(X.median())\n",
    "    print(f\"    âœ“ Filled with median\")\n",
    "else:\n",
    "    print(f\"\\n  âœ“ No missing values\")\n",
    "\n",
    "# Get target\n",
    "y = df['y'].astype(int)\n",
    "\n",
    "print(f\"\\nFinal dataset: {X.shape}\")\n",
    "print(f\"Features used: {X.columns.tolist()}\")\n",
    "print(f\"Class balance: {y.value_counts(normalize=True).round(3).to_dict()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "print(\"\\nSplitting data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"  Train: {X_train.shape}\")\n",
    "print(f\"  Test: {X_test.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DEFINE MODELS\n",
    "# ============================================================================\n",
    "print(\"\\nSetting up models...\")\n",
    "models = {\n",
    "    'logreg': Pipeline([\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "    ]),\n",
    "    'rf': Pipeline([\n",
    "        ('clf', RandomForestClassifier(n_estimators=200, max_depth=10, \n",
    "                                      random_state=42, class_weight='balanced'))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Try to add XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    models['xgb'] = Pipeline([\n",
    "        ('clf', xgb.XGBClassifier(\n",
    "            use_label_encoder=False, \n",
    "            eval_metric='logloss', \n",
    "            random_state=42,\n",
    "            max_depth=6,\n",
    "            n_estimators=200\n",
    "        ))\n",
    "    ])\n",
    "    print(\"  âœ“ XGBoost available\")\n",
    "except:\n",
    "    print(\"  âš  XGBoost not available\")\n",
    "    # Try LightGBM as fallback\n",
    "    try:\n",
    "        import lightgbm as lgb\n",
    "        models['lgbm'] = Pipeline([\n",
    "            ('clf', lgb.LGBMClassifier(random_state=42, n_estimators=200))\n",
    "        ])\n",
    "        print(\"  âœ“ LightGBM available\")\n",
    "    except:\n",
    "        print(\"  âš  LightGBM not available\")\n",
    "\n",
    "print(f\"\\n  Models to train: {list(models.keys())}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN & EVALUATE MODELS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING MODELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    print(f\"\\n[{name.upper()}]\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Train\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    proba = pipe.predict_proba(X_test)[:, 1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "    \n",
    "    # Metrics\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    prauc = average_precision_score(y_test, proba)\n",
    "    prec = precision_score(y_test, pred, zero_division=0)\n",
    "    rec = recall_score(y_test, pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, pred, zero_division=0)\n",
    "    brier = brier_score_loss(y_test, proba)\n",
    "    \n",
    "    results.append({\n",
    "        'model': name, \n",
    "        'auc': auc, \n",
    "        'pr_auc': prauc, \n",
    "        'precision': prec, \n",
    "        'recall': rec, \n",
    "        'f1': f1, \n",
    "        'brier': brier\n",
    "    })\n",
    "    \n",
    "    print(f\"  AUC:       {auc:.3f}\")\n",
    "    print(f\"  PR-AUC:    {prauc:.3f}\")\n",
    "    print(f\"  Precision: {prec:.3f}\")\n",
    "    print(f\"  Recall:    {rec:.3f}\")\n",
    "    print(f\"  F1:        {f1:.3f}\")\n",
    "    print(f\"  Brier:     {brier:.3f}\")\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(pipe, OUT / f\"model_{name}.joblib\")\n",
    "    print(f\"  âœ“ Saved: model_{name}.joblib\")\n",
    "    \n",
    "    # Save predictions\n",
    "    preds_df = pd.DataFrame({\n",
    "        'PatientID': df.loc[X_test.index, 'PatientID'],\n",
    "        'y_true': y_test.values,\n",
    "        'y_proba': proba,\n",
    "        'y_pred': pred\n",
    "    })\n",
    "    preds_df.to_csv(OUT / f\"predictions_{name}.csv\", index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE MODEL COMPARISON\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "scores_df = pd.DataFrame(results).sort_values('auc', ascending=False)\n",
    "print(\"\\n\" + scores_df.to_string(index=False))\n",
    "\n",
    "scores_df.to_csv(OUT / \"model_scores.csv\", index=False)\n",
    "print(f\"\\nâœ“ Saved: model_scores.csv\")\n",
    "\n",
    "# Select best model\n",
    "best_name = scores_df.iloc[0]['model']\n",
    "best_model = joblib.load(OUT / f\"model_{best_name}.joblib\")\n",
    "print(f\"\\nðŸ† Best model: {best_name.upper()} (AUC={scores_df.iloc[0]['auc']:.3f})\")\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE IMPORTANCE (for tree models)\n",
    "# ============================================================================\n",
    "if best_name in ['rf', 'xgb', 'lgbm']:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FEATURE IMPORTANCE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    estimator = best_model.named_steps['clf']\n",
    "    \n",
    "    # Get feature importance\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': estimator.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    importance.to_csv(OUT / f\"feature_importance_{best_name}.csv\", index=False)\n",
    "    print(f\"\\nâœ“ Saved: feature_importance_{best_name}.csv\")\n",
    "    \n",
    "    print(\"\\nTop 10 features:\")\n",
    "    print(importance.head(10).to_string(index=False))\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_n = min(15, len(importance))\n",
    "    plt.barh(range(top_n), importance['importance'].head(top_n))\n",
    "    plt.yticks(range(top_n), importance['feature'].head(top_n))\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top {top_n} Features - {best_name.upper()}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT / f\"feature_importance_{best_name}.png\", dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"âœ“ Saved: feature_importance_{best_name}.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# SHAP EXPLANATIONS (FIXED)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SHAP EXPLANATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    \n",
    "    print(f\"\\nComputing SHAP values for {best_name}...\")\n",
    "    \n",
    "    if best_name in ['rf', 'xgb', 'lgbm']:\n",
    "        # Tree models: use TreeExplainer (fast)\n",
    "        estimator = best_model.named_steps.get('clf', best_model)\n",
    "        explainer = shap.TreeExplainer(estimator)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        \n",
    "        # Handle multiclass output (take positive class)\n",
    "        if isinstance(shap_values, list):\n",
    "            sv = shap_values[1]\n",
    "        else:\n",
    "            sv = shap_values\n",
    "        \n",
    "        # Summary plot\n",
    "        shap.summary_plot(sv, X_test, show=False, max_display=20)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUT / f\"shap_summary_{best_name}.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"âœ“ Saved: shap_summary_{best_name}.png\")\n",
    "        \n",
    "        # Dot plot (FIXED: use summary_plot with plot_type)\n",
    "        shap.summary_plot(sv, X_test, plot_type=\"dot\", show=False, max_display=20)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUT / f\"shap_dot_{best_name}.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"âœ“ Saved: shap_dot_{best_name}.png\")\n",
    "        \n",
    "    else:\n",
    "        # Logistic Regression: use LinearExplainer (faster than Kernel)\n",
    "        print(\"  Using LinearExplainer for logistic regression...\")\n",
    "        # Get the actual LR model and scaler\n",
    "        scaler = best_model.named_steps.get('scaler')\n",
    "        clf = best_model.named_steps.get('clf')\n",
    "        \n",
    "        # Transform data\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Create explainer\n",
    "        explainer = shap.LinearExplainer(clf, X_test_scaled)\n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "        \n",
    "        # Summary plot\n",
    "        shap.summary_plot(shap_values, X_test, show=False, max_display=20)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUT / f\"shap_summary_{best_name}.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"âœ“ Saved: shap_summary_{best_name}.png\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš  SHAP computation failed: {e}\")\n",
    "    print(\"  Continuing without SHAP explanations...\")\n",
    "\n",
    "# ============================================================================\n",
    "# ROC & PR CURVES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PERFORMANCE CURVES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, proba_best)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f\"AUC = {roc_auc_score(y_test, proba_best):.3f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random')\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=12)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=12)\n",
    "plt.title(f\"ROC Curve - {best_name.upper()}\", fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT / \"roc_curve_best.png\", dpi=150)\n",
    "plt.close()\n",
    "print(\"âœ“ Saved: roc_curve_best.png\")\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, proba_best)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, linewidth=2, \n",
    "         label=f\"PR-AUC = {average_precision_score(y_test, proba_best):.3f}\")\n",
    "plt.axhline(y=y_test.mean(), color='k', linestyle='--', alpha=0.5, \n",
    "            label=f'Baseline = {y_test.mean():.3f}')\n",
    "plt.xlabel(\"Recall\", fontsize=12)\n",
    "plt.ylabel(\"Precision\", fontsize=12)\n",
    "plt.title(f\"Precision-Recall Curve - {best_name.upper()}\", fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT / \"pr_curve_best.png\", dpi=150)\n",
    "plt.close()\n",
    "print(\"âœ“ Saved: pr_curve_best.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# FULL DATASET PREDICTIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERATING FULL DATASET PREDICTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "full_proba = best_model.predict_proba(X)[:, 1]\n",
    "full_pred = (full_proba >= 0.5).astype(int)\n",
    "\n",
    "out_full = pd.DataFrame({\n",
    "    'PatientID': df['PatientID'],\n",
    "    'y_true': df['y'],\n",
    "    'y_proba': full_proba,\n",
    "    'y_pred': full_pred,\n",
    "    'risk_category': pd.cut(full_proba, bins=[0, 0.3, 0.7, 1.0], \n",
    "                            labels=['Low', 'Medium', 'High'])\n",
    "})\n",
    "\n",
    "out_full.to_csv(OUT / \"predictions_full_bestmodel.csv\", index=False)\n",
    "print(f\"âœ“ Saved: predictions_full_bestmodel.csv ({len(out_full)} patients)\")\n",
    "\n",
    "print(\"\\nRisk distribution:\")\n",
    "print(out_full['risk_category'].value_counts().sort_index())\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL REPORT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERATING REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with open(OUT / \"model_report.txt\", \"w\") as f:\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"ML MODEL TRAINING REPORT - PATIENT RESPONSE PREDICTION\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Best Model: {best_name.upper()}\\n\")\n",
    "    f.write(f\"AUC: {scores_df.iloc[0]['auc']:.3f}\\n\")\n",
    "    f.write(f\"PR-AUC: {scores_df.iloc[0]['pr_auc']:.3f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"MODEL COMPARISON\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(scores_df.to_string(index=False) + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"DATASET INFO\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(f\"Total patients: {len(df)}\\n\")\n",
    "    f.write(f\"Features used: {X.shape[1]}\\n\")\n",
    "    f.write(f\"Class balance: {y.value_counts(normalize=True).to_dict()}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"RECOMMENDATIONS\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"1. Validate threshold (0.5) against business objectives\\n\")\n",
    "    f.write(\"2. Consider calibration for probability interpretation\\n\")\n",
    "    f.write(\"3. Monitor model performance on new data\\n\")\n",
    "    f.write(\"4. Investigate misclassified high-risk patients\\n\")\n",
    "    f.write(\"5. Consider temporal validation (train on older data, test on recent)\\n\")\n",
    "\n",
    "print(\"âœ“ Saved: model_report.txt\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PIPELINE COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nðŸ“‚ All outputs saved to: {OUT}\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(f\"  â€¢ model_*.joblib ({len(models)} models)\")\n",
    "print(f\"  â€¢ predictions_*.csv ({len(models)} + 1 files)\")\n",
    "print(f\"  â€¢ model_scores.csv\")\n",
    "print(f\"  â€¢ feature_importance_*.csv/.png\")\n",
    "print(f\"  â€¢ shap_summary_*.png\")\n",
    "print(f\"  â€¢ roc_curve_best.png\")\n",
    "print(f\"  â€¢ pr_curve_best.png\")\n",
    "print(f\"  â€¢ model_report.txt\")\n",
    "print(\"\\nðŸ† Best model:\", best_name.upper())\n",
    "print(f\"   AUC: {scores_df.iloc[0]['auc']:.3f}\")\n",
    "print(f\"   Ready for deployment!\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69774fdf-b3cb-4d9b-8c09-a7921473a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "04_production_artifacts.py\n",
    "Generate calibration, optimal thresholds, SHAP explanations for Power BI\n",
    "Run AFTER 03_ml_train_compare.py\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "BASE = Path(r\"C:/Users/lakovskr/Desktop/portfolio/AplusA_PoC\")\n",
    "GOLD = BASE / \"gold\"\n",
    "OUT = GOLD\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PRODUCTION ARTIFACTS - CALIBRATION, THRESHOLDS, SHAP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD ARTIFACTS FROM STEP 3\n",
    "# ============================================================================\n",
    "print(\"\\nLoading trained models and data...\")\n",
    "df = pd.read_parquet(GOLD / \"patients_features.parquet\")\n",
    "predictions = pd.read_csv(GOLD / \"predictions_full_bestmodel.csv\")\n",
    "\n",
    "# Load best model\n",
    "best_model = joblib.load(GOLD / \"model_rf.joblib\")\n",
    "print(f\"âœ“ Loaded RandomForest model\")\n",
    "\n",
    "# Recreate X, y (same as training)\n",
    "drop_cols = [\n",
    "    'PatientID', 'Verbatim', 'SurveyDate', \n",
    "    'first_visit', 'last_visit', 'age_bucket',\n",
    "    'future_resp_rate', 'future_prob_mean', 'ResponseScore'\n",
    "]\n",
    "candidate_features = [c for c in df.columns if c not in drop_cols]\n",
    "X = df[candidate_features].copy()\n",
    "\n",
    "# Encode categoricals\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "if categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "X = X.select_dtypes(include=[np.number]).fillna(X.median())\n",
    "y = (df['future_resp_rate'] > 0).astype(int)\n",
    "\n",
    "# Train-test split (same random state as training)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# A. CALIBRATION (Platt Scaling)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"A. PROBABILITY CALIBRATION (Platt Scaling)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calibrate on test set\n",
    "print(\"\\nCalibrating model probabilities...\")\n",
    "calibrated_model = CalibratedClassifierCV(best_model, method='sigmoid', cv='prefit')\n",
    "calibrated_model.fit(X_test, y_test)\n",
    "\n",
    "# Get calibrated probabilities for full dataset\n",
    "proba_calibrated = calibrated_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Save calibrated model\n",
    "joblib.dump(calibrated_model, OUT / \"model_rf_calibrated.joblib\")\n",
    "print(\"âœ“ Saved: model_rf_calibrated.joblib\")\n",
    "\n",
    "# Update predictions with calibrated probs\n",
    "predictions['y_proba_calibrated'] = proba_calibrated\n",
    "predictions.to_csv(OUT / \"predictions_full_calibrated.csv\", index=False)\n",
    "print(\"âœ“ Saved: predictions_full_calibrated.csv\")\n",
    "\n",
    "# Calibration curve comparison\n",
    "proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "proba_test_calib = calibrated_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fraction_positives_orig, mean_predicted_orig = calibration_curve(\n",
    "    y_test, proba_test, n_bins=10, strategy='quantile'\n",
    ")\n",
    "fraction_positives_calib, mean_predicted_calib = calibration_curve(\n",
    "    y_test, proba_test_calib, n_bins=10, strategy='quantile'\n",
    ")\n",
    "\n",
    "# Plot calibration\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Perfect calibration')\n",
    "plt.plot(mean_predicted_orig, fraction_positives_orig, 's-', \n",
    "         label='Original RF', linewidth=2, markersize=8)\n",
    "plt.plot(mean_predicted_calib, fraction_positives_calib, 'o-', \n",
    "         label='Calibrated RF (Platt)', linewidth=2, markersize=8)\n",
    "plt.xlabel('Mean Predicted Probability', fontsize=12)\n",
    "plt.ylabel('Fraction of Positives', fontsize=12)\n",
    "plt.title('Calibration Curve Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT / \"calibration_curve.png\", dpi=150)\n",
    "plt.close()\n",
    "print(\"âœ“ Saved: calibration_curve.png\")\n",
    "\n",
    "print(\"\\nCalibration metrics:\")\n",
    "print(f\"  Original Brier score: {((proba_test - y_test)**2).mean():.4f}\")\n",
    "print(f\"  Calibrated Brier score: {((proba_test_calib - y_test)**2).mean():.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# B. OPTIMAL THRESHOLDS (Two Strategies)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"B. THRESHOLD OPTIMIZATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use calibrated probabilities for threshold selection\n",
    "proba_test_final = proba_test_calib\n",
    "\n",
    "# Strategy 1: High Sensitivity (Recall-oriented - catch all positives)\n",
    "print(\"\\nStrategy 1: HIGH SENSITIVITY (Safety/Monitoring)\")\n",
    "print(\"  Goal: Maximize recall, accept lower precision\")\n",
    "\n",
    "# Find threshold that gives 90%+ recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, proba_test_final)\n",
    "high_recall_idx = np.where(recall >= 0.90)[0]\n",
    "if len(high_recall_idx) > 0:\n",
    "    # Pick the one with highest precision among those with 90%+ recall\n",
    "    best_idx = high_recall_idx[np.argmax(precision[high_recall_idx])]\n",
    "    threshold_high_sensitivity = thresholds[best_idx]\n",
    "else:\n",
    "    threshold_high_sensitivity = 0.3\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "pred_hs = (proba_test_final >= threshold_high_sensitivity).astype(int)\n",
    "prec_hs = precision_score(y_test, pred_hs, zero_division=0)\n",
    "rec_hs = recall_score(y_test, pred_hs, zero_division=0)\n",
    "f1_hs = f1_score(y_test, pred_hs, zero_division=0)\n",
    "\n",
    "print(f\"  Threshold: {threshold_high_sensitivity:.3f}\")\n",
    "print(f\"  Precision: {prec_hs:.3f}\")\n",
    "print(f\"  Recall: {rec_hs:.3f}\")\n",
    "print(f\"  F1: {f1_hs:.3f}\")\n",
    "print(f\"  % flagged: {pred_hs.mean():.1%}\")\n",
    "\n",
    "# Strategy 2: High Precision (Top-K targeting for commercial)\n",
    "print(\"\\nStrategy 2: HIGH PRECISION (Commercial Targeting)\")\n",
    "print(\"  Goal: Target top 10% with highest predicted probability\")\n",
    "\n",
    "threshold_top10 = np.percentile(proba_test_final, 90)\n",
    "pred_hp = (proba_test_final >= threshold_top10).astype(int)\n",
    "prec_hp = precision_score(y_test, pred_hp, zero_division=0)\n",
    "rec_hp = recall_score(y_test, pred_hp, zero_division=0)\n",
    "f1_hp = f1_score(y_test, pred_hp, zero_division=0)\n",
    "\n",
    "print(f\"  Threshold: {threshold_top10:.3f}\")\n",
    "print(f\"  Precision: {prec_hp:.3f}\")\n",
    "print(f\"  Recall: {rec_hp:.3f}\")\n",
    "print(f\"  F1: {f1_hp:.3f}\")\n",
    "print(f\"  % flagged: {pred_hp.mean():.1%} (by design)\")\n",
    "\n",
    "# Save thresholds\n",
    "thresholds_df = pd.DataFrame({\n",
    "    'strategy': ['High_Sensitivity', 'High_Precision'],\n",
    "    'threshold': [threshold_high_sensitivity, threshold_top10],\n",
    "    'precision': [prec_hs, prec_hp],\n",
    "    'recall': [rec_hs, rec_hp],\n",
    "    'f1': [f1_hs, f1_hp],\n",
    "    'pct_flagged': [pred_hs.mean(), pred_hp.mean()],\n",
    "    'use_case': ['Safety monitoring - catch all at-risk', \n",
    "                 'Commercial targeting - top decile']\n",
    "})\n",
    "thresholds_df.to_csv(OUT / \"optimal_thresholds.csv\", index=False)\n",
    "print(\"\\nâœ“ Saved: optimal_thresholds.csv\")\n",
    "\n",
    "# Confusion matrices for both strategies\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# High Sensitivity\n",
    "cm_hs = confusion_matrix(y_test, pred_hs)\n",
    "im1 = axes[0].imshow(cm_hs, cmap='Blues')\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_yticks([0, 1])\n",
    "axes[0].set_xticklabels(['Pred Neg', 'Pred Pos'])\n",
    "axes[0].set_yticklabels(['True Neg', 'True Pos'])\n",
    "axes[0].set_title(f'High Sensitivity (Threshold={threshold_high_sensitivity:.3f})', \n",
    "                  fontweight='bold')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = axes[0].text(j, i, f'{cm_hs[i, j]}\\n({cm_hs[i, j]/cm_hs.sum():.1%})',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\", fontsize=11)\n",
    "\n",
    "# High Precision\n",
    "cm_hp = confusion_matrix(y_test, pred_hp)\n",
    "im2 = axes[1].imshow(cm_hp, cmap='Oranges')\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].set_yticks([0, 1])\n",
    "axes[1].set_xticklabels(['Pred Neg', 'Pred Pos'])\n",
    "axes[1].set_yticklabels(['True Neg', 'True Pos'])\n",
    "axes[1].set_title(f'High Precision (Threshold={threshold_top10:.3f})', \n",
    "                  fontweight='bold')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = axes[1].text(j, i, f'{cm_hp[i, j]}\\n({cm_hp[i, j]/cm_hp.sum():.1%})',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\", fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT / \"threshold_comparison.png\", dpi=150)\n",
    "plt.close()\n",
    "print(\"âœ“ Saved: threshold_comparison.png\")\n",
    "\n",
    "# Apply both thresholds to full dataset\n",
    "predictions['pred_high_sensitivity'] = (predictions['y_proba_calibrated'] >= threshold_high_sensitivity).astype(int)\n",
    "predictions['pred_high_precision'] = (predictions['y_proba_calibrated'] >= threshold_top10).astype(int)\n",
    "\n",
    "# Add risk categories with calibrated probs\n",
    "predictions['risk_category'] = pd.cut(\n",
    "    predictions['y_proba_calibrated'],\n",
    "    bins=[0, 0.3, 0.7, 1.0],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "predictions.to_csv(OUT / \"predictions_full_calibrated.csv\", index=False)\n",
    "print(\"âœ“ Updated predictions with both threshold strategies\")\n",
    "\n",
    "# ============================================================================\n",
    "# C. SHAP EXPLANATIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"C. SHAP EXPLANATIONS (Patient-Level)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    print(\"\\nComputing SHAP values for RandomForest...\")\n",
    "    \n",
    "    # Use TreeExplainer for RF\n",
    "    estimator = best_model.named_steps['clf']\n",
    "    explainer = shap.TreeExplainer(estimator)\n",
    "    \n",
    "    # Compute for test set\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    \n",
    "    # Handle multiclass output\n",
    "    if isinstance(shap_values, list):\n",
    "        sv = shap_values[1]  # Positive class\n",
    "    else:\n",
    "        sv = shap_values\n",
    "    \n",
    "    # Summary plot (bar)\n",
    "    shap.summary_plot(sv, X_test, show=False, max_display=15, plot_type='bar')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT / \"shap_summary_bar.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"âœ“ Saved: shap_summary_bar.png\")\n",
    "    \n",
    "    # Summary plot (beeswarm)\n",
    "    shap.summary_plot(sv, X_test, show=False, max_display=15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT / \"shap_summary_beeswarm.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"âœ“ Saved: shap_summary_beeswarm.png\")\n",
    "    \n",
    "    # Waterfall plot for top 3 high-risk patients\n",
    "    print(\"\\nGenerating waterfall plots for top 3 high-risk patients...\")\n",
    "    \n",
    "    # Get top 3 by predicted probability\n",
    "    test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    top3_idx = np.argsort(test_proba)[-3:][::-1]\n",
    "    \n",
    "    for i, idx in enumerate(top3_idx):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.waterfall_plot(\n",
    "            shap.Explanation(\n",
    "                values=sv[idx],\n",
    "                base_values=explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
    "                data=X_test.iloc[idx],\n",
    "                feature_names=X_test.columns.tolist()\n",
    "            ),\n",
    "            show=False,\n",
    "            max_display=10\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUT / f\"shap_waterfall_patient_{i+1}.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"âœ“ Saved: shap_waterfall_patient_1/2/3.png\")\n",
    "    \n",
    "    # Force plot for top patient (HTML)\n",
    "    print(\"\\nGenerating SHAP force plot (HTML)...\")\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
    "        sv[top3_idx[0]],\n",
    "        X_test.iloc[top3_idx[0]],\n",
    "        matplotlib=False\n",
    "    ).save_html(str(OUT / \"shap_force_plot_top_patient.html\"))\n",
    "    print(\"âœ“ Saved: shap_force_plot_top_patient.html\")\n",
    "    \n",
    "    print(\"\\nâœ… SHAP explanations complete\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\nâš ï¸  SHAP not installed\")\n",
    "    print(\"   Install with: pip install shap --break-system-packages\")\n",
    "    print(\"   Skipping SHAP generation...\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸  SHAP computation failed: {e}\")\n",
    "    print(\"   Continuing without SHAP explanations...\")\n",
    "\n",
    "# ============================================================================\n",
    "# D. POWER BI READY DATASETS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"D. POWER BI DATASETS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Main predictions table (already saved above with calibrated probs + thresholds)\n",
    "print(\"\\nâœ“ predictions_full_calibrated.csv\")\n",
    "print(\"  Columns: PatientID, y_true, y_proba, y_proba_calibrated,\")\n",
    "print(\"           pred_high_sensitivity, pred_high_precision, risk_category\")\n",
    "\n",
    "# 2. Thresholds reference table (already saved)\n",
    "print(\"âœ“ optimal_thresholds.csv\")\n",
    "print(\"  Columns: strategy, threshold, precision, recall, f1, pct_flagged, use_case\")\n",
    "\n",
    "# 3. Feature importance (already exists from step 3)\n",
    "if (OUT / \"feature_importance_rf.csv\").exists():\n",
    "    print(\"âœ“ feature_importance_rf.csv (from step 3)\")\n",
    "\n",
    "# 4. Model scores (already exists from step 3)\n",
    "if (OUT / \"model_scores.csv\").exists():\n",
    "    print(\"âœ“ model_scores.csv (from step 3)\")\n",
    "\n",
    "# 5. Create risk distribution summary\n",
    "risk_summary = predictions.groupby('risk_category').agg(\n",
    "    count=('PatientID', 'count'),\n",
    "    pct=('PatientID', lambda x: len(x) / len(predictions)),\n",
    "    avg_proba=('y_proba_calibrated', 'mean'),\n",
    "    actual_response_rate=('y_true', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "risk_summary.to_csv(OUT / \"risk_distribution.csv\", index=False)\n",
    "print(\"âœ“ risk_distribution.csv\")\n",
    "print(\"  Summary stats by risk category\")\n",
    "\n",
    "# 6. Create decile analysis\n",
    "try:\n",
    "    predictions['decile'] = pd.qcut(\n",
    "        predictions['y_proba_calibrated'], \n",
    "        q=10, \n",
    "        labels=False,\n",
    "        duplicates='drop'\n",
    "    ) + 1  # 1-indexed deciles\n",
    "    predictions['decile'] = 'D' + predictions['decile'].astype(str)\n",
    "except ValueError:\n",
    "    # If qcut fails, use percentile ranks\n",
    "    predictions['decile'] = pd.cut(\n",
    "        predictions['y_proba_calibrated'].rank(pct=True),\n",
    "        bins=10,\n",
    "        labels=[f'D{i}' for i in range(1, 11)]\n",
    "    )\n",
    "\n",
    "decile_analysis = predictions.groupby('decile').agg(\n",
    "    n_patients=('PatientID', 'count'),\n",
    "    avg_predicted_prob=('y_proba_calibrated', 'mean'),\n",
    "    actual_response_rate=('y_true', 'mean'),\n",
    "    min_prob=('y_proba_calibrated', 'min'),\n",
    "    max_prob=('y_proba_calibrated', 'max')\n",
    ").reset_index()\n",
    "\n",
    "decile_analysis.to_csv(OUT / \"decile_analysis.csv\", index=False)\n",
    "print(\"âœ“ decile_analysis.csv\")\n",
    "print(\"  Decile-level performance metrics\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRODUCTION ARTIFACTS COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nðŸ“‚ Files created for Power BI:\")\n",
    "print(\"\\nModels:\")\n",
    "print(\"  â€¢ model_rf_calibrated.joblib\")\n",
    "\n",
    "print(\"\\nDatasets:\")\n",
    "print(\"  â€¢ predictions_full_calibrated.csv (MAIN - use this)\")\n",
    "print(\"  â€¢ optimal_thresholds.csv\")\n",
    "print(\"  â€¢ risk_distribution.csv\")\n",
    "print(\"  â€¢ decile_analysis.csv\")\n",
    "print(\"  â€¢ feature_importance_rf.csv (from step 3)\")\n",
    "print(\"  â€¢ model_scores.csv (from step 3)\")\n",
    "\n",
    "print(\"\\nVisualizations:\")\n",
    "print(\"  â€¢ calibration_curve.png\")\n",
    "print(\"  â€¢ threshold_comparison.png\")\n",
    "print(\"  â€¢ shap_summary_bar.png (if SHAP installed)\")\n",
    "print(\"  â€¢ shap_summary_beeswarm.png (if SHAP installed)\")\n",
    "print(\"  â€¢ shap_waterfall_patient_*.png (if SHAP installed)\")\n",
    "print(\"  â€¢ roc_curve_best.png (from step 3)\")\n",
    "print(\"  â€¢ pr_curve_best.png (from step 3)\")\n",
    "\n",
    "print(\"\\nðŸ“Š Key Numbers for Laurent:\")\n",
    "print(f\"  â€¢ Calibrated model AUC: Same as original (~0.94)\")\n",
    "print(f\"  â€¢ High Sensitivity threshold: {threshold_high_sensitivity:.3f} (catches {rec_hs:.1%} of positives)\")\n",
    "print(f\"  â€¢ High Precision threshold: {threshold_top10:.3f} (top 10%, precision {prec_hp:.1%})\")\n",
    "print(f\"  â€¢ Total patients: {len(predictions)}\")\n",
    "print(f\"  â€¢ High risk patients: {(predictions['risk_category']=='High').sum()} ({(predictions['risk_category']=='High').mean():.1%})\")\n",
    "\n",
    "print(\"\\nâœ… Ready for Power BI integration\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43b62c8-9b53-4457-9a2a-5b289e853fea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m predictions_df = ... \u001b[38;5;66;03m# Your code to create the predictions dataframe\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# --- Add these two new lines ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPatients Features Columns:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mpatients_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m.tolist())\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPredictions Columns:\u001b[39m\u001b[33m\"\u001b[39m, predictions_df.columns.tolist())\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# --- This is your existing code ---\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'ellipsis' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# --- This is your existing code ---\n",
    "patients_df = ... # Your code to create the features dataframe\n",
    "predictions_df = ... # Your code to create the predictions dataframe\n",
    "\n",
    "# --- Add these two new lines ---\n",
    "print(\"Patients Features Columns:\", patients_df.columns.tolist())\n",
    "print(\"Predictions Columns:\", predictions_df.columns.tolist())\n",
    "\n",
    "# --- This is your existing code ---\n",
    "patients_df.to_csv('data/patients_features.csv', index=False)\n",
    "predictions_df.to_csv('data/predictions_full_bestmodel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd3dd7-d4c0-46a1-a56d-4328c279e850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
